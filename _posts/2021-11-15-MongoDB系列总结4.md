---
layout:     post
title:      MongoDB系列总结4
subtitle:   MongoDB进阶知识
date:       2021-11-14
author:     Yikun Chen
header-img: img/background/header.png
catalog: true
tags:
    - mongodb

---


# MongoDB系列总结4

MongoDB进阶知识
--

## 集群

mongodb集群的提供了数据冗余并增加了数据可用性。对于不同数据库服务器上的多个数据副本，复制为防止单台数据库服务器故障提供了一定程度的容错能力。在某些情况下，复制可以提高读取性能，因为客户端可以将读操作发送到不同的服务器上。在不同的数据中心维护数据副本可以提高分布式应用程序的数据本地化和可用性。您还可以维护额外的副本以实现特殊用途，比如灾难恢复、报告或备份。

### 节点类型

#### 主节点

主节点是唯一一个可以接受写操作的成员。MongoDB在主节点 上应用写操作，然后将这些操作记录到主节点的oplog中。从节点成员复制这个日志然后应用到它们的数据集中。在下图的三成员副本集中，主节点接受所有写操作。然后从节点复制oplog应用至它们的数据集中。副本集所有的成员都可以接受读操作。但是，默认情况下，应用程序会将其读操作定向至主节点。副本集最多有一个主节点。 如果当前主节点不可用，一个选举会抉择出新的主节点。

![picture1](/img/mongodb/replica.svg)

#### 从节点

一个从节点维护了主节点数据集的一个副本。为了复制数据，从节点通过异步的方式将主节点oplog 应用至自己的数据集中。一个副本集可以有一个或多个从节点。虽然客户端不能将数据写入到从节点，但客户端可以由从节点读取数据。从节点可以成为主节点。如果当前主节点不可用，副本集会发起选举来选择哪个从节点成为新的主节点。您可以出于特殊目的来配置从节点成员。您可以配置一个从节点用于:阻止它在选举中成为主节点，适用于将该节点部署在备用数据中心或者充当一个冷备节点。防止应用程序从它读取数据，适用于在该节点上运行需要与正常流量分离的应用程序。保持一个运行的“历史”快照，以便在从某些错误恢复时使用。

#### 仲裁节点

在某些情况下（例如有一个主节点和一个从节点，但由于成本约束无法添加另一个从节点），你可以在副本集中添加一个仲裁节点。仲裁节点没有数据集的副本，并且不能成为主节点。然而，仲裁节点可以参与主节点选举。一个仲裁节点只有 1 票选举权。

### 日志

oplog(操作日志)是一个特殊的有限集合，它对数据库中所存储数据的所有修改操作进行滚动记录。MongoDB在主节点上应用数据库操作，然后将这些操作记录到主节点的oplog上。然后从节点成员会以异步的方式复制并应用这些操作。所有副本集成员都包含一个oplog的副本，其位于local.oplog.rs 集合中，该集合可以让副本集成员维护数据库的当前状态。为了便于复制，所有副本集成员将心跳发送给所有其他成员。任何从节点成员都可以从任何其他成员导入oplog条目。oplog中的每个操作都是幂等的。也就是说，对目标数据集应用一次或多次oplog操作都会产生相同的结果。

### 数据同步

#### 初始化同步

克隆除local数据库之外的所有数据库。为了进行克隆，mongod 扫描每个源数据库中的各个集合，并将所有数据插入到这些集合各自的副本中。
初始化同步在为每个集合复制文档时会建立集合的所有索引。初始化同步会获取在数据复制期间新增的oplog记录。请确保目标成员的local 数据库中有足够的磁盘空间，以便可以在数据复制阶段期间内临时存储这些oplog记录。
对数据集应用所有的更改。使用来自源库的oplog，mongod 更新其数据集以反映副本集的当前状态。当初始化同步完成后，目标成员会从 STARTUP2状态转为SECONDARY状态。

#### 复制数据

从节点成员在初始化同步之后会不断地复制数据。从节点成员从同步源复制oplog ，并以异步的方式应用这些操作 。从节点可以根据ping时间和其他成员复制状态的变化，按需来自动调整它们的同步源。从节点会避免从延迟成员和隐藏成员中同步数据。
MongoDB通过使用多线程批量应用写操作来提高并发。MongoDB根据文档id （WiredTiger）进行分批，同时使用不同的线程应用每组操作。MongoDB总是按照原始的写顺序对给定的文档应用写操作。

#### 副本集成员

一个副本集至多可以有50个成员，但可投票成员最多只能有7个。如果副本集已经有7个有投票权的成员了，那其他的成员只能作为无投票权成员。

### 分片集群

分片是一种将数据分配到多个机器上的方法。MongoDB通过分片技术来支持具有海量数据集和高吞吐量操作的部署方案。数据库系统的数据集或应用的吞吐量比较大的情况下，会给单台服务器的处理能力带来极大的挑战。例如，高查询率会耗尽服务器的CPU资源。工作的数据集大于系统的内存压力、磁盘驱动器的I/O容量。MongoDB通过分片来实现水平扩展。

MongoDB分片集群包括以下组件：

分片：每个shard（分片）包含被分片的数据集中的一个子集。每个分片可以被部署为副本集架构。

mongos：mongos充当查询路由器，在客户端应用程序和分片集群之间提供接口。

config servers：config servers存储了分片集群的元数据和配置信息。

![picture1](/img/mongodb/cluster.svg)

#### 分片的优势
读/写
MongoDB的分布在整个读取和写入负载 碎片的在分片集群，使每个碎片来处理群集操作的一个子集。通过添加更多分片，读取和写入工作负载都可以在集群中水平扩展。对于包含分片键或复合分片键前缀mongos的查询，可以将查询定位到特定分片或分片集。这些有针对性的操作通常比广播到集群中的每个分片更有效 。

存储容量
分片横跨分发数据碎片在集群中，允许每个碎片以包含总簇数据的子集。随着数据集的增长，额外的分片会增加集群的存储容量。

高可用性
将配置服务器和分片部署为副本集提供了更高的可用性。即使一个或多个分片副本集变得完全不可用，分片集群也可以继续执行部分读写。也就是说，虽然无法访问不可用分片上的数据，但针对可用分片的读取或写入仍然可以成功。

#### 注意事项
分片集群基础设施要求和复杂性需要仔细规划、执行和维护。一旦集合被分片，MongoDB 不提供任何方法来取消分片集合的分片。

## 存储引擎

从MongoDB 3.2开始，WiredTiger存储引擎开始作为默认的存储引擎。

### 文档级别的并发

MongoDB在执行写操作时，WiredTiger 在文档级别进行并发控制，就是说，在同一时间，多个写操作能够修改同一个集合中的不同文档；当多个写操作修改同一个文档时，必须以序列化方式执行；这意味着，如果该文档正在被修改，其他写操作必须等待，直到在该文档上的写操作完成之后，其他写操作相互竞争，获胜的写操作在该文档上执行修改操作。

对于大多数读写操作，WiredTiger使用乐观并发控制（optimistic concurrency control），只在Global，database和Collection级别上使用意向锁（Intent Lock），如果WiredTiger检测到两个操作发生冲突时，导致MongoDB将其中一个操作重新执行，这个过程是系统自动完成的。

### 快照与检查点

在Checkpoint操作开始时，WiredTiger提供指定时间点（point-in-time）的数据库快照（Snapshot），该Snapshot呈现的是内存中数据的一致性视图。当向Disk写入数据时，WiredTiger将Snapshot中的所有数据以一致性方式写入到数据文件（Disk Files）中。一旦Checkpoint创建成功，WiredTiger保证数据文件和内存数据是一致性的，因此，Checkpoint担当的是还原点（Recovery Point），Checkpoint操作能够缩短MongoDB从Journal日志文件还原数据的时间。

当WiredTiger创建Checkpoint时，MongoDB将数据刷新到数据文件（Disk Files）中，在默认情况下，WiredTiger创建Checkpoint的时间间隔是60s，或产生2GB的Journal文件。在WiredTiger创建新的Checkpoint期间，上一个Checkpoint仍然是有效的，这意味着，即使MongoDB在创建新的Checkpoint期间遭遇到错误而异常终止运行，只要重启，MongoDB就能从上一个有效的Checkpoint开始还原数据。

当MongoDB以原子方式更新WiredTiger的元数据表，使其引用新的Checkpoint时，表明新的Checkpoint创建成功，MongoDB将老的Checkpoint占用的Disk空间释放。使用WiredTiger 存储引擎，如果没有记录数据更新的日志，MongoDB只能还原到上一个Checkpoint；如果要还原在上一个Checkpoint之后执行的修改操作，必须使用Jounal日志文件。

### 日志

WiredTiger使用预写日志的机制，在数据更新时，先将数据更新写入到日志文件，然后在创建Checkpoint操作开始时，将日志文件中记录的操作，刷新到数据文件，就是说，通过预写日志和Checkpoint，将数据更新持久化到数据文件中，实现数据的一致性。WiredTiger 日志文件会持久化记录从上一次Checkpoint操作之后发生的所有数据更新，在MongoDB系统崩溃时，通过日志文件能够还原从上次Checkpoint操作之后发生的数据更新。

### 数据压缩

WiredTiger压缩存储集合（Collection）和索引（Index），压缩减少Disk空间消耗，但是消耗额外的CPU执行数据压缩和解压缩的操作。

默认情况下，WiredTiger使用块压缩（Block Compression）算法来压缩Collections，使用前缀压缩（Prefix Compression）算法来压缩Indexes，Journal日志文件也是压缩存储的。对于大多数工作负载（Workload），默认的压缩设置能够均衡（Balance）数据存储的效率和处理数据的需求，即压缩和解压的处理速度是非常高的。

### Disk空间回收

当从MongoDB中删除文档（Documents）或集合（Collections）后，MongoDB不会将Disk空间释放给OS，MongoDB在数据文件（Data Files）中维护Empty Records的列表。当重新插入数据后，MongoDB从Empty Records列表中分配存储空间给新的Document，因此，不需要重新开辟空间。为了更新有效的重用Disk空间，必须重新整理数据碎片。

WiredTiger使用compact 命令，移除集合（Collection）中数据和索引的碎片，并将unused的空间释放。在执行compact命令时，MongoDB会对当前的database加锁，阻塞其他操作。在compact命令执行完成之后，mongod会重建集合的所有索引。


参考文献
--

